---
title: middleware24-OEF
date: 2024-12-26
tags: GPU Cluster Management
cover: ../../../assets/posts/projects/AICompiler/middleware24-OEF.png
---

> Optimal Resource Efficiency with Fairness in Heterogeneous GPU Clusters

## 1. 摘要

OEF (Optimal Resource Efficiency with Fairness)是一个新的资源分配框架，专为异构GPU集群中的深度学习训练设计，以实现最优的资源效率并确保用户的多样性公平性。OEF通过将资源效率和公平性整合到全局优化框架中，能够在合作和非合作环境中为用户提供最大化的整体效率和各种公平性保证。

通过在包含24个异构GPU设备的集群中实现OEF原型系统并进行大规模实验，结果表明，OEF能够将整体训练吞吐量提高最多32%，同时与现有最先进的异构感知调度器相比，提高了公平性。

## 2. 问题挑战

- 现有的深度学习调度器在异构GPU集群中提供有限的公平性属性和次优的训练吞吐量；

- 设计挑战源于效率和公平性属性之间的固有冲突；

- 需要一个新的调度策略，既能提供高效率，又能在资源分配中保持公平性。

## 3. 整体设计

OEF资源分配框架如上图所示，旨在解决异构GPU集群中的资源效率与公平性之间的冲突。它通过以下关键组件实现这一目标：
- 全局优化框架：整合资源效率和公平性，以便于同时考虑这两方面的需求；

- 效率与公平性的量化：明确定义和量化效率与公平性，便于在优化问题中进行评估和平衡。主要的speedup矩阵W和allocation矩阵X，分别表示：
    - W训练任务在不同GPU设备上的执行速率与在最慢GPU设备上执行速率的比值。它反映了不同GPU设备处理特定训练任务的性能差异；

    - X用于记录每个用户分配到的每种类型GPU数量的矩阵。它定义了资源分配的具体方案。

![](../../../assets/posts/projects/AICompiler/middleware24-OEF-fig2.png)

### 3.1 非合作环境的解决方案

![](../../../assets/posts/projects/AICompiler/middleware24-OEF-fig1.png)

在非合作环境中，OEF的设计重点在于实现Strategy-Proofness (SP)，确保用户不会通过虚报其作业的加速比来获得不当利益：
- 效率均等分配：设计一个优化问题，确保所有用户获得相同的 (标准化)吞吐量，从而实现Strategy-Proofness；

- 优化问题：构建一个线性优化模型，目标是最大化所有用户的总吞吐量，同时约束条件确保用户间的效率平等。

### 3.2 合作环境的解决方案

![](../../../assets/posts/projects/AICompiler/middleware24-OEF-fig3.png)

在合作环境中，OEF专注于实现Envy-Freeness (EF)和Sharing-Incentive (SI)：
- 优化问题调整：调整优化问题以包含无嫉妒约束，确保每个用户对其分配的资源满意，不会羡慕其他用户的资源分配；

- 共享激励的实现：通过优化问题的设计，当追求无嫉妒时，共享激励自然得到满足，因为最大化整体资源效率会促使资源的公平分配。

### 3.3 权重OEF

为了适应不同用户优先级的情况，OEF引入权重机制：
- 用户权重分配：为每个用户分配权重，反映其重要性或资源需求；

- 速度向量复制：通过复制速度向量多次来适应权重，确保权重较高的用户获得更多的资源。

### 3.4 多类型作业支持

OEF支持用户同时训练不同类型的DL作业：
- 虚拟用户概念：将每种作业类型视为单独的虚拟用户独立处理；

- 权重分配：将用户的权重平均分配给其所有作业类型以确保公平性。

### 3.5 放置优化

OEF的放置优化策略旨在将分数分配转换为整数份额，并考虑长期效率和公平性：
- 四舍五入策略：开发一种策略将每个用户分配的分数转换为整数份额，同时跟踪和调整偏差，以确保长期公平性；

- 网络争用缓解：优化放置方案以减少网络争用，优先考虑分配更多资源给具有更多工作进程的作业。

### 3.6 拖沓效应

OEF通过以下方式减轻拖沓效应：
- GPU类型限制：确保为每个用户分配的GPU类型相邻，减少跨类型放置；

- 极端点定理应用：利用定理限制分配矩阵中的非零元素数量，减少拖沓效应的影响。
